[课程链接](https://www.bilibili.com/video/BV1if4y147hS/?spm_id_from=333.999.0.0&vd_source=8924ad59b4f62224f165e16aa3d04f00)

# 01课程安排

· 深度学习基础——先行神经网络，多层感知机



· 卷积神经网络



· 循环神经网络



· 注意力机制



· 优化算法



· 高性能计算



· 计算机视觉



· 自然语言处理

## 资源

课程主页 https://courses.d2l.ai/zh-v2



教材 https://zh-v2.d2l.ai/



课程论坛 https://discuss.d2l.ai/c/16



pytorch论坛 https://discuss.pytorch.org/

# 02深度学习介绍

# 03安装

使用conda/miniconda环境



参考b站默认收藏夹

# 04数据操作+数据预处理

## 04.1数据操作

介绍了索引二维矩阵的几种方式

```python
[1,2]
[1,:]
[:,1]
[1:3,1:]#[1:3]左闭右开
[::3,::2]
```

## 04.2数据操作实现

讲了一些pytorch的内容

```python
import torch
x = torch.arange(12)
x
#tensor([0,1,2,3,4,5,6,7,8,9,10,11])
x.shape()
#torch.Size([12])
x.numel() #number of element 元素数量
#12
X = x.reshape(3,4)
X
"""
tensor([[0,1,2,3],
		[4,5,6,7],
    	[8,9,10,11]])
"""
torch.zeros(2,3,4)#形状为2，3，4值全0的矩阵
torch.ones(2,3,4)#形状为2，3，4值全1的矩阵
torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])#创建了一个二维数组 当然也可以创建三维
#算术运算符 +   - * / ** 加 减 乘 除 指数(幂运算)
#所有这些运算都是按元素进行的
torch.exp(x)#对所有元素做指数运算

#也可以把多个张量连结在一起
X = torch.arange(12, dtype=torch.float32).reshape(3,4)
Y = torch.tensor([[2.0,1,4,3],[1,2,3,4],[4,3,2,1]])
torch.cat((X,Y),dim=0)
torch.cat((X,Y),dim=1)

X == Y#生成包含True/False的二元张量

X.sum()
#tensor(66.)
```



广播机制 3x1矩阵和1x2矩阵相加会得到3x2的矩阵



用[-1]可以访问最后一个元素



运行一些操作可能会导致为新结果分配内存

```python
before = id(Y) #id返回值是类似C++中指针一样的东西，表示object在python中唯一的标识号
Y = Y + X
id(Y) == before
#out:False
```



执行原地操作

```python
Z = torch.zeros_like(Y)
print('id(Z):',id(Z))
Z[:] = X + Y
print('id(Z):',id(Z))
"""
out:
id(Z):123456
id(Z):123456
"""
#没有创建一个新的Z

before = id(X)
X += Y
id(X) == before
#out:True
#这里也没有创建一个新的X

#总结：X[:]=X+Y 或 X+=Y 可以减少内存开销
```



转换为 NumPy 张量

```python
A = X.numpy()
B = torch.tensor(A)
type(A),type(B)
#out:numpy.ndarray, torch.Tensor
```



将大小为1的张量转换为Python标量

```python
a = torch.tensor([3.5])
a,a.item(),float(a),int(a)
#out:(tensor([3.5000]), 3.5, 3.5, 3)
```



## 04.3数据预处理实现

