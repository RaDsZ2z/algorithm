{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61b6176-cb03-4d52-ac34-581152ddbda6",
   "metadata": {},
   "source": [
    "“图片空间信息不断变小，通道数不断变多，把压缩的抽出来的空间信息放到不同通道里。最后图片高宽变成1x1，通道数非常大，然后做全连接输出”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a2dc45-a7ac-4e8a-ae79-b2b1d33cfc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" #解决运行d2l时内核崩溃\n",
    "# LeNet(LeNet-5) 由两个部分组成：卷积编码器和全连接层密集块\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "class Reshape(torch.nn.Module):\n",
    "    def forward(self,x):\n",
    "        return x.view(-1,1,28,28) # 批量数自适应得到，通道数为1，图片为28X28\n",
    "    \n",
    "net = torch.nn.Sequential(\n",
    "        Reshape(),\n",
    "        #这里的1和6分别是输入通道数和输出通道数\n",
    "        nn.Conv2d(1,6,kernel_size=5,padding=2),nn.Sigmoid(),#6*28*28\n",
    "        nn.AvgPool2d(kernel_size=2,stride=2),#6*14*14\n",
    "        nn.Conv2d(6,16,kernel_size=5),nn.Sigmoid(),#16*10*10\n",
    "        nn.AvgPool2d(kernel_size=2,stride=2),#16*5*5\n",
    "        \n",
    "        #输入X是四维的(批量大小，通道数，高，宽)\n",
    "        #Flatten使其变为二维，保留批量大小，(通道数,宽,高)被平铺到一维了\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "        nn.Linear(120, 84), nn.Sigmoid(),\n",
    "        nn.Linear(84,10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a839a826-33b8-4a23-8e0a-ab7abbc322f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape output shape：\t torch.Size([1, 1, 28, 28])\n",
      "Conv2d output shape：\t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape：\t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape：\t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape：\t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape：\t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape：\t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape：\t torch.Size([1, 400])\n",
      "Linear output shape：\t torch.Size([1, 120])\n",
      "Sigmoid output shape：\t torch.Size([1, 120])\n",
      "Linear output shape：\t torch.Size([1, 84])\n",
      "Sigmoid output shape：\t torch.Size([1, 84])\n",
      "Linear output shape：\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "检查模型 看一下经过每一层后数据的形状\n",
    "size=(批量大小,通道数,高,宽)\n",
    "'''\n",
    "X = torch.rand(size=(1,1,28,28),dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape：\\t',X.shape) # 上一层的输出为这一层的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac709647-28a7-4eb3-8e5f-20643c256490",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''LeNet在Fashion-MNIST数据集上的表现'''\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f36a7d5-c28f-4684-be30-e1a1d400c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''对evaluate_accuracy函数进行轻微的修改'''\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval() # net.eval()开启验证模式，不用计算梯度和更新梯度\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device # 看net.parameters()中第一个元素的device为哪里\n",
    "    metric = d2l.Accumulator(2)\n",
    "    for X, y in data_iter:\n",
    "        if isinstance(X,list):\n",
    "            X = [x.to(device) for x in X] # 如果X是个List，则把每个元素都移到device上\n",
    "        else:\n",
    "            X = X.to(device) # 如果X是一个Tensor，则只用移动一次，直接把X移动到device上\n",
    "        y = y.to(device)\n",
    "        metric.add(d2l.accuracy(net(X),y),y.numel()) # y.numel() 为y元素个数 \n",
    "    return metric[0]/metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "135ee935-71c6-4750-ac6c-675d8fff3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''为了使用GPU，还需要一点小改动'''\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"Train a model with a GPU\"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight) # 根据输入、输出大小，使得随即初始化后，输入和输出的的方差是差不多的              \n",
    "            \n",
    "    net.apply(init_weights)\n",
    "    print('training on',device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(),lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch',xlim=[1,num_epochs],\n",
    "                           legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        \n",
    "        for i, (X,y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], d2l.accuracy(y_hat,y),X.shape[0])                \n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            \n",
    "            if(i+1) % (num_batches//5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i+1) / num_batches,\n",
    "                            (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "        \n",
    "    print(f'loss {train_l:.3f},train acc {train_acc:.3f},'\n",
    "         f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec'\n",
    "         f'on{str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48cb2739-3509-4dd6-b93e-fa1ab20233b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function xavier_uniform_ in module torch.nn.init:\n",
      "\n",
      "xavier_uniform_(tensor: torch.Tensor, gain: float = 1.0, generator: Optional[torch._C.Generator] = None) -> torch.Tensor\n",
      "    Fill the input `Tensor` with values using a Xavier uniform distribution.\n",
      "\n",
      "    The method is described in `Understanding the difficulty of training\n",
      "    deep feedforward neural networks` - Glorot, X. & Bengio, Y. (2010).\n",
      "    The resulting tensor will have values sampled from\n",
      "    :math:`\\mathcal{U}(-a, a)` where\n",
      "\n",
      "    .. math::\n",
      "        a = \\text{gain} \\times \\sqrt{\\frac{6}{\\text{fan\\_in} + \\text{fan\\_out}}}\n",
      "\n",
      "    Also known as Glorot initialization.\n",
      "\n",
      "    Args:\n",
      "        tensor: an n-dimensional `torch.Tensor`\n",
      "        gain: an optional scaling factor\n",
      "        generator: the torch Generator to sample from (default: None)\n",
      "\n",
      "    Examples:\n",
      "        >>> w = torch.empty(3, 5)\n",
      "        >>> nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu'))\n",
      "\n",
      "    Note:\n",
      "        Be aware that ``fan_in`` and ``fan_out`` are calculated assuming\n",
      "        that the weight matrix is used in a transposed manner,\n",
      "        (i.e., ``x @ w.T`` in ``Linear`` layers, where ``w.shape = [fan_out, fan_in]``).\n",
      "        This is important for correct initialization.\n",
      "        If you plan to use ``x @ w``, where ``w.shape = [fan_in, fan_out]``,\n",
      "        pass in a transposed weight matrix, i.e. ``nn.init.xavier_uniform_(w.T, ...)``.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.init.xavier_uniform_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc845ba3-0c52-41e2-ae60-abf29a5d8c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 是 CPU 版本\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查 PyTorch 是否支持 CUDA\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda_available:\n",
    "    print(\"PyTorch 是 GPU 版本\")\n",
    "    print(\"可用的 GPU 数量:\", torch.cuda.device_count())\n",
    "    print(\"当前使用的 GPU 名称:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"PyTorch 是 CPU 版本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab93db0-dcd0-46d0-92f0-dd9d4309748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cpu\n"
     ]
    }
   ],
   "source": [
    "# 训练和评估LeNet-5模型\n",
    "lr, num_epochs = 0.9, 10\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
