# 19.卷积层

## 19.1.从全连接到卷积

$$
h_{i,j}=\sum_{k,l}W_{i,j,k,l}x_{k,l}=\sum_{a,b}v_{i,j,a,b}x_{i+a,j+b}
$$

实际上这个公式描述的就是二维图片和二维卷积核的卷积操作（[什么是卷积](https://www.bilibili.com/video/BV1VV411478E/?spm_id_from=333.788.top_right_bar_window_custom_collection.content.click&vd_source=8924ad59b4f62224f165e16aa3d04f00)）  

其中`v`是卷积核矩阵，`x`是图片矩阵  

**原则1 平移不变性**

+ x的平移会导致h的平移 


$$
h_{i,j}=\sum_{a,b}^{}v_{i,j,a,b}x_{i+a,j+b}
$$


+ v不应该依赖于(i,j) （也就是无论i,j如何变化，v都是那个v）
+ 解决方案: $v_{i,j,a,b}=v_{a,b}$


$$
h_{i,j}=\sum_{a,b}^{}v_{a,b}x_{i+a,j+b}
$$

​	

这就是2维~~卷积~~交叉相关

**原则2 局部性**

换了一种形式，当 $|a|,|b|>\Delta$ 时，使得 $v_{a,b=0}$


$$
h_{i,j}=\sum_{a=-\Delta}^{\Delta}\sum_{b=-\Delta}^{\Delta}v_{a,b}x_{i+a,j+b}
$$

## 19.2.卷积层

**交叉相关VS卷积**

区别就是在索引卷积核时，两者索引顺序是对称的，为了计算方便使用前者  

它们在实际使用中没有区别

**一维和三维交叉计算**

这里主要关注的是二维计算，一维和三维的计算也是有的  

一维：文本、语言、时序序列


$$
y_i=\sum_{a=1}^{h}w_ax_{i+a}
$$


三维：视频、医学图像、气象地图


$$
y_{i,j,k}=\sum_{a=1}^{h}\sum_{b=1}^{w}\sum_{c=1}^{d}w_{a,b,c}x_{i+a,j+b,k+c}
$$

**总结**

+ 卷积层将输入和核矩阵进行交叉相关，加上偏移后得到输出
+ 核矩阵和偏移是可学习的参数
+ 核矩阵的大小是超参数

## 19.3.代码

手写了梯度下降  

`19.3.卷积层代码`

# 20.卷积层里的填充和步幅

[链接](https://www.bilibili.com/video/BV1Th411U7UN?spm_id_from=333.788.recommend_more_video.0&vd_source=8924ad59b4f62224f165e16aa3d04f00)  

## 20.1.填充和步幅

按照之前的做法，图像与卷积核进行运算之后会变小。如果不想让它变小呢？  

**填充**  

在输入的周围添加额外的行/列

**步幅**  

步幅是指行/列的滑动步长

**总结**

+ 填充和步幅是卷积层的超参数
+ 填充在输入周围添加额外的行/列，来控制输出形状的减少量
+ 步幅是每次滑动核窗口时的行/列的步长，可以成倍地减少输出形状

## 20.2.代码

`20.2.卷积层里的填充和步幅.ipynb`

# 21.卷积层里的多输入多输出通道

[链接](https://www.bilibili.com/video/BV1MB4y1F7of/?spm_id_from=333.1387.upload.video_card.click&vd_source=8924ad59b4f62224f165e16aa3d04f00)

## 21.1.多输入输出通道

前面用到的代码   `conv2d = nn.Conv2d(1, 1, kernel_size=(1,2), bias=False)`   这里的前两个参数就分别是 输入，输出通道数  

彩色图像可能有RGB三个通道（大小为200x200的图片，矩阵大小是200x200x3）



![21_1](./img/21_1.png)

![21_2](./img/21_2.png)

多输入通道相比单输入通道，**输入**和**卷积核**多了一个输入通道数维度 $c_i$  

两个输入和两个卷积核分别运算得到两个矩阵，再把两个矩阵加起来得到最终的输出结果。

这个例子里卷积核矩阵数量是2，实际上数量可以更多，无论是多少，把这一系列的二维卷积核看成一个**三维卷积核**



![21_3](./img/21_3.png)

多输出通道相比单输出通道，**卷积核**和**输出**多了一个输出通道数维度 $c_o$  

上面提到了**三维卷积核**，一个三维卷积核对应一个输出通道，有多少个三维卷积核就有多少个输出通道  

所以这里的卷积核是**四维**的

![21_4](./img/21_4.png)

相当于输出形状为 $n_hn_w \times c_i$ ，权重为形状 $c_i \times c_o$ 的全连接层

**总结**

+ 输出通道数是卷积层的超参数
+ 每个输入通道有独立的二维卷积核，所有通道结果相加得到一个输出通道结果
+ 每个输出通道有独立的三维卷积核

## 21.2.代码实现

见`21.2.卷积层里的多输入多输出通道代码实现`  

这里写一下 `zip` 函数的作用及用法

```python
for item in zip(para1,para2,para3,...):
    do something
```

`zip`返回一个可迭代对象，其元素数量为各参数的第一维大小，若各参数第一维大小不同则取最小值

其中`item`是一个tuple类型，其长度为参数个数。

`items`中各元素由各参数第一维的各个元素拼接而成

# 22.池化层

[课程链接](https://www.bilibili.com/video/BV1EV411j7nX/?spm_id_from=333.1387.upload.video_card.click&vd_source=8924ad59b4f62224f165e16aa3d04f00)

## 22.1.池化层

一般是先有卷积输出的结果，然后再对这个结果做池化

+ 池化层返回窗口中最大或平均值
+ 缓解卷积层对位置的敏感性
+ 同样有窗口大小、填充、和步幅作为超参数

## 22.2.代码实现

略

# 23.经典卷积神经网络 LeNet

[课程链接](https://www.bilibili.com/video/BV1t44y1r7ct/?spm_id_from=333.1387.upload.video_card.click&vd_source=8924ad59b4f62224f165e16aa3d04f00)

## 23.1.LeNet

这里提到了**手写数字识别**，我也在B站收藏了一个[10分钟入门神经网络 PyTorch 手写数字识别](https://www.bilibili.com/video/BV1GC4y15736/?spm_id_from=333.1387.favlist.content.click)视频，还没看。

![23_1](./img/23_1.png)

**总结**

+ LeNet是早期成功的神经网络
+ 先使用卷积层来学习图片空间信息
+ 然后使用全连接层来转换到类别空间

到这里我发现我对通道数对改变没有直观的感受，应该回到`21.卷积层里的多输入多输出通道`看看  

好的我看完了并且对该章节的笔记进行了一些补充

## 23.2.代码



