# 19.卷积层

## 19.1.从全连接到卷积

$$
h_{i,j}=\sum_{k,l}W_{i,j,k,l}x_{k,l}=\sum_{a,b}v_{i,j,a,b}x_{i+a,j+b}
$$

实际上这个公式描述的就是二维图片和二维卷积核的卷积操作（[什么是卷积](https://www.bilibili.com/video/BV1VV411478E/?spm_id_from=333.788.top_right_bar_window_custom_collection.content.click&vd_source=8924ad59b4f62224f165e16aa3d04f00)）  

其中`v`是卷积核矩阵，`x`是图片矩阵  

**原则1 平移不变性**

+ x的平移会导致h的平移 


$$
h_{i,j}=\sum_{a,b}^{}v_{i,j,a,b}x_{i+a,j+b}
$$


+ v不应该依赖于(i,j) （也就是无论i,j如何变化，v都是那个v）
+ 解决方案: $v_{i,j,a,b}=v_{a,b}$


$$
h_{i,j}=\sum_{a,b}^{}v_{a,b}x_{i+a,j+b}
$$

​	

这就是2维~~卷积~~交叉相关

**原则2 局部性**

换了一种形式，当 $|a|,|b|>\Delta$ 时，使得 $v_{a,b=0}$


$$
h_{i,j}=\sum_{a=-\Delta}^{\Delta}\sum_{b=-\Delta}^{\Delta}v_{a,b}x_{i+a,j+b}
$$

## 19.2.卷积层

**交叉相关VS卷积**

区别就是在索引卷积核时，两者索引顺序是对称的，为了计算方便使用前者  

它们在实际使用中没有区别

**一维和三维交叉计算**

这里主要关注的是二维计算，一维和三维的计算也是有的  

一维：文本、语言、时序序列


$$
y_i=\sum_{a=1}^{h}w_ax_{i+a}
$$


三维：视频、医学图像、气象地图


$$
y_{i,j,k}=\sum_{a=1}^{h}\sum_{b=1}^{w}\sum_{c=1}^{d}w_{a,b,c}x_{i+a,j+b,k+c}
$$

**总结**

+ 卷积层将输入和核矩阵进行交叉相关，加上偏移后得到输出
+ 核矩阵和偏移是可学习的参数
+ 核矩阵的大小是超参数

## 19.3.代码

手写了梯度下降  

`19.3.卷积层代码`

# 20.卷积层里的填充和步幅

[链接](https://www.bilibili.com/video/BV1Th411U7UN?spm_id_from=333.788.recommend_more_video.0&vd_source=8924ad59b4f62224f165e16aa3d04f00)  

## 20.1.填充和步幅

按照之前的做法，图像与卷积核进行运算之后会变小。如果不想让它变小呢？  

**填充**  

在输入的周围添加额外的行/列

**步幅**  

步幅是指行/列的滑动步长

**总结**

+ 填充和步幅是卷积层的超参数
+ 填充在输入周围添加额外的行/列，来控制输出形状的减少量
+ 步幅是每次滑动核窗口时的行/列的步长，可以成倍地减少输出形状

## 20.2.代码

`20.2.卷积层里的填充和步幅.ipynb`

# 21.卷积层里的多输入多输出通道

[链接](https://www.bilibili.com/video/BV1MB4y1F7of/?spm_id_from=333.1387.upload.video_card.click&vd_source=8924ad59b4f62224f165e16aa3d04f00)

## 21.1.多输入输出通道

前面用到的代码   `conv2d = nn.Conv2d(1, 1, kernel_size=(1,2), bias=False)`   这里的前两个参数就分别是 输入，输出通道数  

彩色图像可能有RGB三个通道（大小为200x200的图片，矩阵大小是200x200x3）



![21_1](./img/21_1.png)

![21_2](./img/21_2.png)

多输入通道相比单输入通道，**输入**和**卷积核**多了一个输入通道数维度 $c_i$  

两个输入和两个卷积核**分别运算**得到两个矩阵，再把两个矩阵加起来得到最终的输出结果。  

（注意这里二维输入矩阵的数量等于二维卷积核的数量）

这个例子里二维矩阵(输入/卷积核)的数量2，实际上数量可以更多。若干个二维矩阵就是三维矩阵啦，因此这里有一个**三维输入矩阵**和一个**三维卷积核**



![21_3](./img/21_3.png)

多输出通道相比单输出通道，**卷积核**和**输出**多了一个输出通道数维度 $c_o$  

上面提到了**三维卷积核**，一个三维卷积核对应一个输出通道，有多少个三维卷积核就有多少个输出通道  

所以多输出通道时有**四维卷积核**

![21_4](./img/21_4.png)

相当于输出形状为 $n_hn_w \times c_i$ ，权重为形状 $c_i \times c_o$ 的全连接层

**总结**

+ 输出通道数是卷积层的超参数
+ 每个输入通道有独立的二维卷积核，所有通道结果相加得到一个输出通道结果
+ 每个输出通道有独立的三维卷积核

## 21.2.代码实现

见`21.2.卷积层里的多输入多输出通道代码实现`  

这里写一下 `zip` 函数的作用及用法

```python
for item in zip(para1,para2,para3,...):
    do something
```

`zip`返回一个可迭代对象，其元素数量为各参数的第一维大小，若各参数第一维大小不同则取最小值

其中`item`是一个tuple类型，其长度为参数个数。

`items`中各元素由各参数第一维的各个元素拼接而成

# 22.池化层

[课程链接](https://www.bilibili.com/video/BV1EV411j7nX/?spm_id_from=333.1387.upload.video_card.click&vd_source=8924ad59b4f62224f165e16aa3d04f00)

## 22.1.池化层

一般是先有卷积输出的结果，然后再对这个结果做池化

+ 池化层返回窗口中最大或平均值
+ 缓解卷积层对位置的敏感性
+ 同样有窗口大小、填充、和步幅作为超参数

## 22.2.代码实现

略

# 23.经典卷积神经网络 LeNet

[课程链接](https://www.bilibili.com/video/BV1t44y1r7ct/?spm_id_from=333.1387.upload.video_card.click&vd_source=8924ad59b4f62224f165e16aa3d04f00)

## 23.1.LeNet

这里提到了**手写数字识别**，我也在B站收藏了一个[10分钟入门神经网络 PyTorch 手写数字识别](https://www.bilibili.com/video/BV1GC4y15736/?spm_id_from=333.1387.favlist.content.click)视频，还没看。

![23_1](./img/23_1.png)

**总结**

+ LeNet是早期成功的神经网络
+ 先使用卷积层来学习图片空间信息
+ 然后使用全连接层来转换到类别空间

到这里我发现我对通道数对改变没有直观的感受，应该回到`21.卷积层里的多输入多输出通道`看看  

好的我看完了并且对该章节的笔记进行了一些补充  

然后觉得代码也应该看看  

好的看完了，又对该章节的笔记和代码进行了一些修改

## 23.2.代码

本节代码见`23.2.经典卷积神经网络.ipynb`

突然又对`nn.Conv2d`没感觉，看起来学得很不扎实。它是一个卷积操作，下面代码是一个参考。可以结合`21.卷积层里的多输入多输出通道`理解。

```python
import torch
import torch.nn as nn

# 定义输入张量，形状为 (batch_size, channels, height, width)
input_tensor = torch.randn(4, 3, 32, 32)  # 4个样本，3个输入通道，32x32的图像

# 创建一个卷积层
conv_layer_1 = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3)  # 输出通道数为4
conv_layer_2 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)  # 输出通道数为8

# 前向传播
output_tensor_1 = conv_layer_1(input_tensor)
output_tensor_2 = conv_layer_2(input_tensor)
print(conv_layer_1.weight.shape) #卷积核形状
print("输出张量形状 (4 通道):", output_tensor_1.shape)
print(conv_layer_2.weight.shape) #卷积核形状
print("输出张量形状 (8 通道):", output_tensor_2.shape)
'''
orch.Size([4, 3, 3, 3])
输出张量形状 (4 通道): torch.Size([4, 4, 30, 30])
torch.Size([8, 3, 3, 3])
输出张量形状 (8 通道): torch.Size([4, 8, 30, 30])
'''
```

第一个卷积核的形状是`[4,3,3,3]`前两个维度大小分别表示输出通道和输入通道，后两个维度是二维卷积核大小

第一个输出张量的形状是`[4,4,30,30]`，第一个4是样本数，第二个4是输出通道数，



顺便写一下`nn.Linear`（线性层/全连接层）

```python
import torch
import torch.nn as nn

# 定义输入张量，形状为 (batch_size, in_features)
input_tensor = torch.randn(3, 4)  # 3个样本，4个输入特征

# 创建一个线性层
linear_layer = nn.Linear(in_features=4, out_features=2)

# 前向传播
output_tensor = linear_layer(input_tensor)

print("输入张量形状:", input_tensor.shape)
print("权重矩阵形状:", linear_layer.weight.shape)  # 输出权重矩阵的形状
print("偏置项形状:", linear_layer.bias.shape)
print("输出张量形状:", output_tensor.shape)
'''
输入张量形状: torch.Size([3, 4])
权重矩阵形状: torch.Size([2, 4])
偏置项形状: torch.Size([2])
输出张量形状: torch.Size([3, 2])
'''
```

这里查看权重矩阵形状其实是有些多余的，如果具体的数学实现不关心可以隐去这个信息。  

可以注意，输入矩阵和输出矩阵相比，行数（样本数）是不变的，列数（特征数量）是会变的  

所以`nn.Linear`的两个参数分别是输入特征数和输出特征数  



均值池化层：`nn.AvgPool2d(kernel_size=2, stride=2)`

```python
nn.AvgPool2d(kernel_size=2,stride=2)
```

## 23.3.QA

> 2025.07.29，我开始看这一节QA了，隔了一个多月又捡起来现在有点云里雾里的，加油~
>
> 每一条QA视频李沐老师都像闲聊一样，随意讨论各种奇奇怪怪的问题，让我感觉缓解了很多学习中的疲惫枯燥

卷积层每一层学到什么是可以可视化的 https://poloclub.github.io/cnn-explainer/  

实际生产中经常不需要很大的训练数据集也可以训练出效果不错的模型

# 24.深度卷积神经网络 AlexNet

## 24.1.AlexNet

“这是引起深度学习热潮的第一个网络”

“构造更深的神经网络相当于消耗更多的算力去挖掘数据里面的信息”

> 2025.07.30 听到一半发现很多之前的概念都不清晰了，决定先复习一下（从自动求导开始），顺手把“手写数字识别”做一做

> 2025.08.01 复习了一些概念，手写数字识别做完了，过程中看了  [一条科普视频](https://www.bilibili.com/video/BV1atCRYsE7x/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&vd_source=8924ad59b4f62224f165e16aa3d04f00)  我回来了

