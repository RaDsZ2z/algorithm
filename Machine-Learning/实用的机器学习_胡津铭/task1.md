第一次课后作业

# 1.机器学习问题

## (a) 从下列词语中选择正确的词描述下列的任务
A）Suspervised Learning 有监督学习
B）Unsuspervised Learning 无监督学习
C）Not Learning
D）Classification 分类
E）Regression 回归
F）Clustering 聚类
G）Dimensionality Reduction 降维

1）将几千张艺术画按照艺术风格分类
2）暴搜解数独
3）识别手写数字
4）在2D或3D空间中可视化非常高维的数据
5）根据之前病人的记录，预测当前病人的手术成功率
6）根据几千个人的姓名和性别，决定新的人的姓名是男的女的
7）发现社交网络中的人群社区
8）利用历史股价预测未来股价
9）将图片映射为64位整数，相似图片间的汉明距离较小
## （b）
“为了充分利用可用的数据资源，我们应该使用所有的数据来训练我们的学习模型，并选择在整个数据集上最大化性能的参数。”这个说法对吗，证明你的答案

是不对的
1.应该拿出一部分数据作为测试数据
2.调整参数使得在训练数据中表现得最好，往往会导致过拟合使得模型效果变差

# 2.贝叶斯决策规则
## （a）
有三个盒子，其中一个有奖品。当你选择其中一个盒子B1后，另外一个盒子B2将会被打开（B2是不包含奖品的）。现在你有第二次选择机会，你可以继续选择B1或者选择B3，最好的选择是什么？

（i）B1盒子包含奖品的先验概率是多少 1/3

（ii）如果B1包含奖品，那么B2不包含奖品的可能性概率是多少 1/2

（iii）给出B2不包含奖品，B1包含奖品的后验概率是多少 2/3

（iv）根据贝叶斯判别法，你应该改变选择吗 应该
## （b）
现在用贝叶斯决策来做一个二类分类器。引用bayes_decision_rule文件夹中的代码和run.m/run.ipynb中的主骨架代码。在data.mat中存储了两个类。每个类都包含有1维特征的训练集和测试集。

（i）完成给定特定类别的每个特征的可能性计算（在likelihood.m/likelihood.py）。并且用最大似然估计计算测试样本（在run.m/run.ipynb）的错误数量。显示$P(x|w_i)$ 的分布并报告测试误差。

（ii）完成给定特定类别的每个特征的后验概率计算（在posterior.m/posterior.py中）。并且用最优贝叶斯决策计算错误分类的测试样本数（在inrun.m/run.ipynb中）。显示 $P(w_i|x)$ 的分布，并报告测试误差

（iii）我们可以采取{$a_1,a_2$}两种行动，它们的loss matrix如下表
展示可以得到的最小总风险 $(R=\sum_{x} min_i R(a_i|x))$

表格见原pdf
# 3.高斯判别分析与MLE
高斯判别分析：似然概率采用了高斯多元分布

给定数据集，数据集有m个(x,y)，x是二元数据对，y是0或1。我们假设这些样本是由两个高斯分布中的一个独立生成的

此处省略两个等式

y的先验概率是

此处省略一个等式

代码在 $gaussian_discriminant$ 文件夹中

## （a）
给一个新的数据点 $x = (x_1,x_2)$ 计算后验概率

省略一个公式

为了简化计算， 做了一些调整 见原pdf文件，决策边界是什么？
```
Q: 
Σ−1
k   (x−μk) 是什么

A:
这个表达式 Σ^-1_k (x-μ_k) 表示的是多元高斯分布中的马氏距离（Mahalanobis distance）。

具体解释如下:

Σ_k 表示第 k 个类别的协方差矩阵。
Σ^-1_k 表示 Σ_k 的逆矩阵。
x 表示一个待分类的样本向量。
μ_k 表示第 k 个类别的均值向量。
(x-μ_k) 表示样本向量 x 与第 k 个类别均值向量 μ_k 的差向量。
Σ^-1_k (x-μ_k) 表示将该差向量乘以协方差矩阵的逆矩阵,得到一个新的向量。
最终, Σ^-1_k (x-μ_k) 表示样本 x 与第 k 个类别的马氏距离。
```

# 4.朴素贝叶斯文本分类器
在这个问题中，您将使用Naive Bayes方法实现一个文本分类器，即一个接受传入电子邮件并将其分类为阳性（垃圾邮件）或阴性（非垃圾邮件/火腿）的分类器。数据在hw1_data.zip中。由于MATLAB不擅长文本处理，也缺乏一些有用的数据结构，TA编写了一些Python脚本来将电子邮件文本转换为MATLAB可以读取的数字。骨架代码是run.m/run.ipynb（在text_classification文件夹中）

在这项任务中，您可以使用任何您喜欢的编程语言来构建文本分类器，而不是遵循TA的Python脚本和run.m/run.ipynb。我们更鼓励你以这种方式完成任务，因为你会更好地了解功能的来源，标签、电子邮件和单词之间的关系，以及其他细节。

write by myself:
频数统计的应该是 该单词在多少封邮件中出现了，而非在邮件中出现了多少次

## 这里是一些可能有用的信息
### i）
单词、文档和标签之间的关系：理论上， $P(word_i=N|SPAM)=P(word_i=N｜documentType_j)P(documentType_j|SPAM)$ 应该成立。

其中 $documentType_j$ 是文档的类型，例如家庭邮件会有更多关于家庭成员和房子的单词，工作邮件会有更多关于商业的单词，游戏广告邮件会有更多单词像'play now'。但是我们不能包含太多的文档类型，那不是朴素贝叶斯关心的。为了简化，在训练中我们丢弃文档信息并混合所有单词以生成 $P(word_i|SPAM)$ 和 $P(word_i|HAM)$ 表示SPAM/HAM邮件中的单词为 $word_i$ 的可能性。因此$P(word_i=N|SPAM)=P(word_i|SPAM)^N$

### ii）
记得增加Laplace smoothing
### iii）
计算似然时，用取log相加代替直接相乘

## question
### （a）
将你所学的模型可视化以获得更多的洞察力通常是有用的。通过查找词汇表中比例
$\frac{P(word_i|SPAM)}{P(word_i|HAM)}$
最高的单词，列出最能代表SPAM类别的前10个单词。
### （b）
你的垃圾邮件过滤器在测试集上的准确性是多少？
### （c）
正确与否：一个99%准确率的模型总是一个好模型。为什么？（提示：当垃圾邮件和垃圾邮件的比例为1:99时，请考虑垃圾邮件过滤器的情况）
### （d）
具有以下混淆矩阵

|   |Spam(label)|Ham(label)|
|---|---        |---|
|Spam(predict)  |TP|FP|
|Ham(predict)   |FN|TN|

计算precision和recal （precision和recal的解释在record文件）
